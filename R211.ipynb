{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5294f68b",
      "metadata": {
        "id": "5294f68b"
      },
      "source": [
        "femのサロゲートモデル学習用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb4657c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# --- Colab/ローカル両対応フラグ ---\n",
        "USE_COLAB = False  # TrueならColab用、Falseならローカル用\n",
        "\n",
        "if USE_COLAB:\n",
        "    # Colab用: パッケージインストール\n",
        "    !pip install torch numpy pyvista pyvistaqt tqdm vtk pandas\n",
        "\n",
        "    # Colab用: データダウンロード＆解凍\n",
        "    import os\n",
        "    import zipfile\n",
        "    DATA_URL = \"https://github.com/WOCae/R211/raw/main/vtu.zip\"\n",
        "    os.makedirs('vtu', exist_ok=True)\n",
        "    !wget -O data_files.zip \"{DATA_URL}\"\n",
        "    with zipfile.ZipFile('data_files.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('vtu')\n",
        "    print(\"Colab: データ解凍完了\")\n",
        "else:\n",
        "    # ローカル用: パッケージインストール（必要ならコメント解除）\n",
        "    # !pip install torch numpy pyvista pyvistaqt tqdm vtk pandas\n",
        "\n",
        "    # ローカル用: データは既に配置済みと仮定（vtuフォルダが存在）\n",
        "    print(\"ローカル: vtuフォルダが存在する前提で進みます\")\n",
        "\n",
        "# 共通: vtuファイル一覧取得\n",
        "import glob\n",
        "vtu_files = sorted(glob.glob(\"vtu/**/*.vtu\", recursive=True))\n",
        "print(f\"vtuファイル数: {len(vtu_files)}\")\n",
        "if len(vtu_files) > 0:\n",
        "    print(f\"最初のファイル: {vtu_files[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791c27ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "# --- 設定の一括管理（メモリ節約モード） ---\n",
        "class Config:\n",
        "    # 3Dグリッド解像度\n",
        "    nx, ny, nz = 24, 24, 24\n",
        "\n",
        "    # 荷重の正規化係数\n",
        "    load_norm = 10000.0\n",
        "\n",
        "    # 物理量のスケール（正規化・復元用）\n",
        "    scales = {\n",
        "        'ux': 1e-4, 'uy': 1e-4, 'uz': 1e-4,\n",
        "        'mises': 1e7,\n",
        "        'disp': 1e-4,\n",
        "        'stress': 1e7\n",
        "    }\n",
        "\n",
        "    # デバイス設定\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 可視化・復元用の定数\n",
        "    NORM_DISP = 1e-4\n",
        "    NORM_STRESS = 1e7\n",
        "    LOAD_NORM_FACTOR = 10000.0\n",
        "\n",
        "    # 物理座標の範囲（必要なら追加）\n",
        "    x_range = (0.0, 10.0)\n",
        "    y_range = (0.0, 10.0)\n",
        "    z_range = (0.0, 100.0)\n",
        "\n",
        "\n",
        "print(f\"Using device: {Config.device}\")\n",
        "print(f\"Grid size: {Config.nx}x{Config.ny}x{Config.nz}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd41156b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyvista as pv\n",
        "import numpy as np\n",
        "\n",
        "def load_case(vtu_path):\n",
        "    \"\"\"1つのVTUファイルから節点座標, 変位, ミーゼス応力を読み込む\"\"\"\n",
        "    mesh = pv.read(vtu_path)\n",
        "    pts = mesh.points.astype(np.float32)\n",
        "    disp = mesh.point_data[\"Displacement\"].astype(np.float32)\n",
        "    mises = mesh.point_data[\"von Mises Stress\"].astype(np.float32)\n",
        "    return pts, disp, mises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af56c4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.interpolate import NearestNDInterpolator\n",
        "\n",
        "def interpolate_to_grid_3d_optimized(pts, disp, mises):\n",
        "    points = pts[:, :3]\n",
        "    gx = np.linspace(Config.x_range[0], Config.x_range[1], Config.nx, dtype=np.float32)\n",
        "    gy = np.linspace(Config.y_range[0], Config.y_range[1], Config.ny, dtype=np.float32)\n",
        "    gz = np.linspace(Config.z_range[0], Config.z_range[1], Config.nz, dtype=np.float32)\n",
        "    grid_x, grid_y, grid_z = np.meshgrid(gx, gy, gz, indexing='ij')\n",
        "    target_points = np.stack([grid_x.ravel(), grid_y.ravel(), grid_z.ravel()], axis=-1)\n",
        "    values = np.column_stack([disp[:,0], disp[:,1], disp[:,2], mises])\n",
        "    interp = NearestNDInterpolator(points, values)\n",
        "    interpolated = interp(target_points)\n",
        "    result_grid = interpolated.reshape(Config.nx, Config.ny, Config.nz, 4)\n",
        "    ux = result_grid[..., 0]\n",
        "    uy = result_grid[..., 1]\n",
        "    uz = result_grid[..., 2]\n",
        "    ms = result_grid[..., 3]\n",
        "    return ux, uy, uz, ms\n",
        "\n",
        "def make_inp_out(pts, disp, mises, load_value):\n",
        "    ux, uy, uz, ms = interpolate_to_grid_3d_optimized(pts, disp, mises)\n",
        "    geo_mask = np.ones((Config.nx, Config.ny, Config.nz), dtype=np.float32)\n",
        "    fix_mask = np.zeros_like(geo_mask)\n",
        "    fix_mask[:, :, 0] = 1.0\n",
        "    load_mask = np.zeros_like(geo_mask)\n",
        "    load_mask[:, :, -1] = 1.0\n",
        "    val_channel = np.full_like(geo_mask, load_value, dtype=np.float32)\n",
        "    inp = np.stack([geo_mask, fix_mask, load_mask, val_channel], axis=0)\n",
        "    ux_n = ux / Config.scales['disp']\n",
        "    uy_n = uy / Config.scales['disp']\n",
        "    uz_n = uz / Config.scales['disp']\n",
        "    ms_n = ms / Config.scales['stress']\n",
        "    out = np.stack([ux_n, uy_n, uz_n, ms_n], axis=0)\n",
        "    return inp, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e546fcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "vtu_files = sorted(glob.glob(\"vtu/**/*.vtu\", recursive=True))\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "print(\"Processing VTU -> 3D grids...\")\n",
        "for vtu_path in tqdm(vtu_files, total=len(vtu_files)):\n",
        "    stem = os.path.splitext(os.path.basename(vtu_path))[0]\n",
        "    try:\n",
        "        _, load_str = stem.split(\"_\", 1)\n",
        "        load_val = float(load_str)\n",
        "    except Exception:\n",
        "        raise ValueError(f\"Could not parse load from file name: {stem}\")\n",
        "    pts, disp, mises = load_case(vtu_path)\n",
        "    load_norm = load_val / Config.load_norm\n",
        "    inp, out = make_inp_out(pts, disp, mises, load_norm)\n",
        "    inp = np.moveaxis(inp, 0, -1).astype(np.float32)\n",
        "    out = np.moveaxis(out, 0, -1).astype(np.float32)\n",
        "    inputs.append(inp)\n",
        "    outputs.append(out)\n",
        "\n",
        "X_all = np.stack(inputs, axis=0)\n",
        "Y_all = np.stack(outputs, axis=0)\n",
        "X_torch = torch.from_numpy(X_all).float()\n",
        "Y_torch = torch.from_numpy(Y_all).float()\n",
        "print(f\"Input shape:  {X_torch.shape}\")\n",
        "print(f\"Output shape: {Y_torch.shape}\")\n",
        "dataset = TensorDataset(X_torch, Y_torch)\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf71dc20",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_summary = []\n",
        "\n",
        "for vtu_path in vtu_files:\n",
        "    stem = os.path.splitext(os.path.basename(vtu_path))[0]\n",
        "    _, load_str = stem.split(\"_\", 1)\n",
        "    load_val = float(load_str)\n",
        "    pts, disp, mises = load_case(vtu_path)\n",
        "    summary = {\n",
        "        \"File Name\": stem,\n",
        "        \"Load [N]\": load_val,\n",
        "        \"Uz_Min [m]\": np.min(disp[:, 2]),\n",
        "        \"Uz_Max [m]\": np.max(disp[:, 2]),\n",
        "        \"Max Mises [Pa]\": np.max(mises)\n",
        "    }\n",
        "    data_summary.append(summary)\n",
        "\n",
        "df_train = pd.DataFrame(data_summary)\n",
        "display(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f4e068",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.fft as fft\n",
        "\n",
        "class SpectralConv3d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes_x, modes_y, modes_z):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes_x = modes_x\n",
        "        self.modes_y = modes_y\n",
        "        self.modes_z = modes_z\n",
        "        self.weight_real = nn.Parameter(\n",
        "            torch.randn(in_channels, out_channels, modes_x, modes_y, modes_z) * 0.1\n",
        "        )\n",
        "        self.weight_imag = nn.Parameter(\n",
        "            torch.randn(in_channels, out_channels, modes_x, modes_y, modes_z) * 0.1\n",
        "        )\n",
        "\n",
        "    def compl_mul3d(self, input, weight_real, weight_imag):\n",
        "        real = torch.einsum(\"bixyz,ioxyz->boxyz\", input.real, weight_real) - \\\n",
        "               torch.einsum(\"bixyz,ioxyz->boxyz\", input.imag, weight_imag)\n",
        "        imag = torch.einsum(\"bixyz,ioxyz->boxyz\", input.real, weight_imag) + \\\n",
        "               torch.einsum(\"bixyz,ioxyz->boxyz\", input.imag, weight_real)\n",
        "        return torch.complex(real, imag)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize, channels, nx, ny, nz = x.shape\n",
        "        x_ft = fft.rfftn(x, dim=[-3, -2, -1], norm=\"ortho\")\n",
        "        out_ft = torch.zeros(\n",
        "            batchsize, self.out_channels, x_ft.size(-3), x_ft.size(-2), x_ft.size(-1),\n",
        "            dtype=torch.cfloat, device=x.device\n",
        "        )\n",
        "        kx, ky, kz = self.modes_x, self.modes_y, self.modes_z\n",
        "        out_ft[:, :, :kx, :ky, :kz] = self.compl_mul3d(\n",
        "            x_ft[:, :, :kx, :ky, :kz],\n",
        "            self.weight_real, self.weight_imag\n",
        "        )\n",
        "        return fft.irfftn(out_ft, s=(nx, ny, nz), dim=[-3, -2, -1], norm=\"ortho\")\n",
        "\n",
        "class FNO3d(nn.Module):\n",
        "    def __init__(self, in_channels=4, out_channels=4, width=32, modes=8):\n",
        "        super().__init__()\n",
        "        self.width = width\n",
        "        self.fc_in = nn.Linear(in_channels, width)\n",
        "        self.convs = nn.ModuleList([SpectralConv3d(width, width, modes, modes, modes) for _ in range(4)])\n",
        "        self.ws = nn.ModuleList([nn.Conv3d(width, width, 1) for _ in range(4)])\n",
        "        self.fc_out1 = nn.Linear(width, 128)\n",
        "        self.fc_out2 = nn.Linear(128, out_channels)\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc_in(x)\n",
        "        x = x.permute(0, 4, 1, 2, 3)\n",
        "        for conv, w in zip(self.convs, self.ws):\n",
        "            x1 = conv(x)\n",
        "            x2 = w(x)\n",
        "            x = self.act(x1 + x2)\n",
        "        x = x.permute(0, 2, 3, 4, 1)\n",
        "        x = self.act(self.fc_out1(x))\n",
        "        x = self.fc_out2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a1e5c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = FNO3d(\n",
        "    in_channels=4,\n",
        "    out_channels=4,\n",
        "    width=32,\n",
        "    modes=8,\n",
        ").to(Config.device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "print(\"Start 3D FNO training...\")\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(Config.device)\n",
        "        yb = yb.to(Config.device)\n",
        "        pred = model(xb)\n",
        "        loss = loss_fn(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1:3d} / 50, Loss = {avg_loss:.6e}\")\n",
        "print(\"Training Finished (3D FNO).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86f3979",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import torch\n",
        "\n",
        "# --- 任意荷重ケースでの3D推論 ---\n",
        "\n",
        "# 1. 入力と同じ形のマスクを作るために、どれか1つ既存ケースのVTUを基準にする\n",
        "base_vtu = vtu_files[0]  # 形状は全ケース共通想定\n",
        "pts_base, disp_base, mises_base = load_case(base_vtu)\n",
        "\n",
        "# 2. 3Dグリッド座標は学習時と同じ Config の範囲を使用\n",
        "nx, ny, nz = Config.nx, Config.ny, Config.nz\n",
        "\n",
        "# Geometry / BC / Load のマスク生成\n",
        "geo_mask  = np.ones((nx, ny, nz), dtype=np.float32)\n",
        "fix_mask  = np.zeros_like(geo_mask, dtype=np.float32); fix_mask[:, :, 0]  = 1.0\n",
        "load_mask = np.zeros_like(geo_mask, dtype=np.float32); load_mask[:, :, -1] = 1.0\n",
        "\n",
        "# 3. 任意荷重値（N）を指定\n",
        "any_load_N = 2000.0\n",
        "load_value_norm = any_load_N / Config.load_norm\n",
        "val_channel = np.full_like(geo_mask, load_value_norm, dtype=np.float32)\n",
        "\n",
        "# 4. 入力テンソルを作成\n",
        "inp_np = np.stack([geo_mask, fix_mask, load_mask, val_channel], axis=-1)\n",
        "inp_torch = torch.from_numpy(inp_np).unsqueeze(0).to(Config.device)\n",
        "\n",
        "# 5. 推論\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model(inp_torch)\n",
        "\n",
        "pred_np = pred.squeeze(0).cpu().numpy()\n",
        "\n",
        "# 6. 物理量に復元\n",
        "ux_pred = pred_np[..., 0] * Config.scales['disp']\n",
        "uy_pred = pred_np[..., 1] * Config.scales['disp']\n",
        "uz_pred = pred_np[..., 2] * Config.scales['disp']\n",
        "mises_pred = pred_np[..., 3] * Config.scales['stress']\n",
        "\n",
        "# 荷重点（x, y 中央, z=最大）のインデックス\n",
        "ix = ux_pred.shape[0] // 2\n",
        "iy = ux_pred.shape[1] // 2\n",
        "iz = ux_pred.shape[2] - 1\n",
        "\n",
        "# 物理座標\n",
        "x_phys = np.linspace(Config.x_range[0], Config.x_range[1], ux_pred.shape[0])[ix]\n",
        "y_phys = np.linspace(Config.y_range[0], Config.y_range[1], ux_pred.shape[1])[iy]\n",
        "z_phys = np.linspace(Config.z_range[0], Config.z_range[1], ux_pred.shape[2])[iz]\n",
        "\n",
        "print(\"=\"*40)\n",
        "print(f\"★ 予測結果サマリー（荷重: {any_load_N:.1f} N）\")\n",
        "print(f\"荷重点インデックス: (ix, iy, iz) = ({ix}, {iy}, {iz})\")\n",
        "print(f\"荷重点物理座標: (x, y, z) = ({x_phys:.2f}, {y_phys:.2f}, {z_phys:.2f})\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Ux (荷重点) : {ux_pred[ix, iy, iz]:.3e} [m]\")\n",
        "print(f\"Uy (荷重点) : {uy_pred[ix, iy, iz]:.3e} [m]\")\n",
        "print(f\"Uz (荷重点) : {uz_pred[ix, iy, iz]:.3e} [m]\")\n",
        "print(f\"von Mises応力 (荷重点) : {mises_pred[ix, iy, iz]/1e6:.3f} [MPa]\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# 7. 代表スライスの簡易可視化\n",
        "y_mid = ny // 2\n",
        "x_min, x_max = Config.x_range\n",
        "z_min, z_max = Config.z_range\n",
        "\n",
        "ux_xz = ux_pred[:, y_mid, :]\n",
        "uy_xz = uy_pred[:, y_mid, :]\n",
        "uz_xz = uz_pred[:, y_mid, :]\n",
        "mises_xz = mises_pred[:, y_mid, :]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
        "fig.suptitle(f\"Predicted fields (x-z mid-y slice, Load = {any_load_N} N)\")\n",
        "\n",
        "im0 = axes[0].imshow(ux_xz.T, origin='lower', cmap='jet', extent=[x_min, x_max, z_min, z_max], aspect='auto')\n",
        "axes[0].set_title('Ux [m] (x-z, mid-y)')\n",
        "axes[0].set_xlabel('x [mm]')\n",
        "axes[0].set_ylabel('z [mm]')\n",
        "plt.colorbar(im0, ax=axes[0])\n",
        "\n",
        "im1 = axes[1].imshow(uy_xz.T, origin='lower', cmap='jet', extent=[x_min, x_max, z_min, z_max], aspect='auto')\n",
        "axes[1].set_title('Uy [m] (x-z, mid-y)')\n",
        "axes[1].set_xlabel('x [mm]')\n",
        "axes[1].set_ylabel('z [mm]')\n",
        "plt.colorbar(im1, ax=axes[1])\n",
        "\n",
        "im2 = axes[2].imshow(uz_xz.T, origin='lower', cmap='jet', extent=[x_min, x_max, z_min, z_max], aspect='auto')\n",
        "axes[2].set_title('Uz [m] (x-z, mid-y)')\n",
        "axes[2].set_xlabel('x [mm]')\n",
        "axes[2].set_ylabel('z [mm]')\n",
        "plt.colorbar(im2, ax=axes[2])\n",
        "\n",
        "im3 = axes[3].imshow(mises_xz.T, origin='lower', cmap='jet', extent=[x_min, x_max, z_min, z_max], aspect='auto')\n",
        "axes[3].set_title('von Mises [Pa] (x-z, mid-y)')\n",
        "axes[3].set_xlabel('x [mm]')\n",
        "axes[3].set_ylabel('z [mm]')\n",
        "plt.colorbar(im3, ax=axes[3])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82cd8721",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyvista as pv\n",
        "import os\n",
        "\n",
        "# 1. 保存先ディレクトリ作成\n",
        "os.makedirs(\"result\", exist_ok=True)\n",
        "\n",
        "# 2. グリッド座標生成\n",
        "gx = np.linspace(Config.x_range[0], Config.x_range[1], nx)\n",
        "gy = np.linspace(Config.y_range[0], Config.y_range[1], ny)\n",
        "gz = np.linspace(Config.z_range[0], Config.z_range[1], nz)\n",
        "grid = pv.RectilinearGrid(gx, gy, gz)\n",
        "\n",
        "# 3. RectilinearGrid → UnstructuredGrid に変換\n",
        "ugrid = grid.cast_to_unstructured_grid()\n",
        "\n",
        "# 4. 推論結果を1次元に変換して格納\n",
        "disp_pred = np.stack([ux_pred, uy_pred, uz_pred], axis=-1).reshape(-1, 3)\n",
        "mises_pred_flat = mises_pred.ravel()\n",
        "\n",
        "ugrid.point_data[\"Displacement\"] = disp_pred\n",
        "ugrid.point_data[\"von Mises Stress\"] = mises_pred_flat\n",
        "\n",
        "# 5. ファイル名を決定して保存\n",
        "result_path = f\"result/predicted_{int(any_load_N)}N.vtu\"\n",
        "ugrid.save(result_path)\n",
        "print(f\"推論結果を {result_path} に保存しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412a8159",
      "metadata": {},
      "outputs": [],
      "source": [
        "# グリッドと変位ベクトル場の可視化例\n",
        "\n",
        "import pyvista as pv\n",
        "\n",
        "# 例: RectilinearGridの可視化\n",
        "p = pv.Plotter()\n",
        "p.add_mesh(grid, show_edges=True, opacity=0.2, color='white')  # グリッド構造の表示\n",
        "\n",
        "# 変位ベクトル場の可視化（UnstructuredGridに変換後）\n",
        "ugrid.point_data[\"Displacement\"] = disp_pred\n",
        "p.add_arrows(ugrid.points, disp_pred, mag=10, color='red')  # 変位ベクトルを矢印で表示（magは倍率）\n",
        "\n",
        "p.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.10.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
